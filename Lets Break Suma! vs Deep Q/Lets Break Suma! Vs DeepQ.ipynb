{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "from mss import mss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import pyautogui\n",
    "import time\n",
    "#env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Extraction(Screen Extraction)\n",
    "from PIL import ImageGrab\n",
    "import cv2\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython: from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "white_template = cv2.imread('templates/white_temp.png',0) \n",
    "blue_template = cv2.imread('templates/blue_temp.png',0)\n",
    "orange_template = cv2.imread('templates/orange_temp.png',0)\n",
    "green_template = cv2.imread('templates/green_temp.png',0)\n",
    "cv2.imshow('image',blue_template)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewards skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial block count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of blocks 21\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "#one scrren\n",
    "bounding_box = {'top': 200, 'left': 630, 'width': 850, 'height': 600} #top left corner of screen\n",
    "sct = mss()\n",
    "sct_img = np.array(sct.grab(bounding_box))\n",
    "gray = cv2.cvtColor(np.array(sct_img), cv2.COLOR_BGR2GRAY)\n",
    "#cv2.imshow('image',gray)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "w,h = blue_template.shape[::-1]  #here\n",
    "result = cv2.matchTemplate(gray,blue_template, cv2.TM_CCOEFF_NORMED) #here \n",
    "f = set()\n",
    "loc = np.where(result >=0.9)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(sct_img,pt,(pt[0] + w, pt[1] + h),(0,255,0),2)\n",
    "    sensitivity = 100\n",
    "    f.add((round(pt[0]/sensitivity), round(pt[1]/sensitivity)))\n",
    "    \n",
    "found_count = len(f)    \n",
    "print(\"amount of blocks\", found_count)\n",
    "cv2.imshow(\"result\", sct_img)\n",
    "#cv2.imshow('screen', np.array(sct_img))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "initial_block_value = found_count\n",
    "print(initial_block_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#screen method 1\n",
    "#img = ImageGrab.grab(bbox=(200,630,850,600)) #bbox specifies specific region (bbox= x,y,width,height *starts top-left)\n",
    "#img_np = np.array(img) #this is the array obtained from conversion\n",
    "#frame = cv2.cvtColor(img_np, cv2.COLOR_BGR2GRAY)\n",
    "#cv2.imshow(\"test\", frame)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "   \n",
    "\n",
    "#one scrren\n",
    "bounding_box = {'top': 200, 'left': 630, 'width': 850, 'height': 600} #top left corner of screen\n",
    "sct = mss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while True:\n",
    "#7 outputs(mouse positions)\n",
    "sct_img = sct.grab(bounding_box)\n",
    "cv2.imshow('screen', np.array(sct_img))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_screen_data2(screen):\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32)/255\n",
    "        screen = torch.from_numpy(screen).float()\n",
    "        screen = transforms.ToPILImage()(screen).convert(\"RGB\")\n",
    "        resize = T.Compose([\n",
    "             T.Resize((600,850))\n",
    "            ,T.ToTensor()\n",
    "        ])\n",
    "        return resize(screen).unsqueeze(0).to(device = \"cuda\") # add a batch dimension (BCHW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_screen_data1(screen):\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32)/255\n",
    "        screen = torch.from_numpy(screen).float()\n",
    "        return screen # add a batch dimension (BCHW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=850x600 at 0x13C210D03C8>\n",
      "(850, 600)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "sct = mss()\n",
    "sct_img =(sct.grab(bounding_box))\n",
    "im = transforms.ToPILImage()(np.array(sct_img)).convert(\"RGB\")\n",
    "#display(im)\n",
    "print(im)\n",
    "print(im.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 850])\n",
      "torch.Size([1, 600, 850])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "bounding_box = {'top': 200, 'left': 630, 'width': 850, 'height': 600} #top left corner of screen\n",
    "sct = mss()\n",
    "sct_img =(sct.grab(bounding_box))\n",
    "sct_img = np.array(sct_img)\n",
    "sct_img = cv2.cvtColor(np.array(sct_img), cv2.COLOR_BGR2GRAY)\n",
    "im = transform_screen_data1(sct_img)\n",
    "sct = mss()\n",
    "sct_img =(sct.grab(bounding_box))\n",
    "sct_img = np.array(sct_img)\n",
    "sct_img = cv2.cvtColor(np.array(sct_img), cv2.COLOR_BGR2GRAY)\n",
    "im1 = transform_screen_data1(sct_img)\n",
    "result = im1 - im\n",
    "print(result.shape)\n",
    "#print(result.squeeze().unsqueeze(dim=0))\n",
    "print(result.squeeze().unsqueeze(dim=0).shape)\n",
    "#cv2.imshow(\"res\",np.array(result))\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "tensor([[[-0.0039, -0.0039, -0.0078,  0.0000],\n",
      "         [-0.0039, -0.0039, -0.0078,  0.0000],\n",
      "         [-0.0039, -0.0039, -0.0078,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0039, -0.0039, -0.0078,  0.0000],\n",
      "         [-0.0039, -0.0039, -0.0078,  0.0000],\n",
      "         [-0.0039, -0.0039, -0.0078,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0039, -0.0039, -0.0078,  0.0000],\n",
      "         [-0.0039, -0.0039, -0.0078,  0.0000],\n",
      "         [-0.0039, -0.0039, -0.0078,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0039,  0.0039,  0.0039,  0.0000],\n",
      "         [ 0.0039,  0.0039,  0.0039,  0.0000],\n",
      "         [ 0.0039,  0.0039,  0.0039,  0.0000],\n",
      "         ...,\n",
      "         [-0.4118, -0.4039, -0.3804,  0.0000],\n",
      "         [-0.4157, -0.4039, -0.3804,  0.0000],\n",
      "         [-0.4157, -0.4039, -0.3804,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0039,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0039,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0039,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.4118, -0.4000, -0.3765,  0.0000],\n",
      "         [-0.4118, -0.4039, -0.3804,  0.0000],\n",
      "         [-0.4118, -0.4039, -0.3804,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.4078, -0.4000, -0.3686,  0.0000],\n",
      "         [-0.4118, -0.4000, -0.3725,  0.0000],\n",
      "         [-0.4118, -0.4000, -0.3725,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "            sct_img =(sct.grab(bounding_box))\n",
    "            second_example2 = transform_screen_data1(sct_img)\n",
    "            sct_img =(sct.grab(bounding_box))\n",
    "            second_example3 = transform_screen_data1(sct_img)\n",
    "            \n",
    "            screen_return = second_example3-second_example2 #(Current minus previous)\n",
    "            print(screen_return.shape[0])\n",
    "            print(screen_return)\n",
    "            cv2.imshow(\"res\",np.array(screen_return))\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#screen method 2(Current)\n",
    "#bounding_box = {'top': 730, 'left': 600, 'width': 850, 'height': 80} #top left corner of screen\n",
    "bounding_box = {'top': 200, 'left': 630, 'width': 850, 'height': 600} #top left corner of screen\n",
    "sct = mss()\n",
    "while True:\n",
    "    sct_img =(sct.grab(bounding_box))\n",
    "    sct_img = np.array(sct_img)\n",
    "    first_example = transform_screen_data1(sct_img) #Transform screen(current screen)/previous\n",
    "    sct_img =(sct.grab(bounding_box))\n",
    "    sct_img = np.array(sct_img)\n",
    "    second_example = transform_screen_data1(sct_img) #Transform screen(current screen)/previous\n",
    "    example = second_example -first_example \n",
    "    #print(example)\n",
    "    #state = example\n",
    "    cv2.imshow('screen',(np.array(example)))\n",
    "    if (cv2.waitKey(1) & 0xFF) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actions Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 outputs\n",
    "def take_actions(action):\n",
    "    if action == 0:\n",
    "        pyautogui.moveTo(640, 400, duration = 0.07) \n",
    "    elif action == 1:\n",
    "        pyautogui.moveTo(740, 400, duration = 0.07) \n",
    "    elif action == 2:\n",
    "        pyautogui.moveTo(840, 400, duration = 0.07)\n",
    "    elif action ==3:\n",
    "        pyautogui.moveTo(940, 400, duration = 0.07) \n",
    "    elif action ==4:\n",
    "        pyautogui.moveTo(1040, 400, duration = 0.07)\n",
    "    elif action ==5:\n",
    "        pyautogui.moveTo(1140, 400, duration = 0.07)\n",
    "    elif action ==6:\n",
    "        pyautogui.moveTo(1240, 400, duration = 0.07)\n",
    "    elif action == 7:\n",
    "        pyautogui.moveTo(1340, 400, duration = 0.07) \n",
    "    elif action == 8:\n",
    "        pyautogui.moveTo(1440, 400, duration = 0.07)\n",
    "    elif action == 9:\n",
    "        pyautogui.moveTo(1500, 400, duration = 0.07)\n",
    "    else:\n",
    "        print(\"Not allowed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experience(state=5, action=6, next_state=7, reward=8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "Xp = namedtuple('Experience',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "Xp_points = Xp(5,6,7,8)\n",
    "Xp_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------DQN(Fully connected)-----------------------------------------#\n",
    "class DQN (nn.Module):\n",
    "    def __init__(self,img_height, img_width):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(in_features = img_height*img_width,out_features=850)\n",
    "        self.layer2      = nn.Linear(in_features = 850, out_features = 200)\n",
    "        self.layer3      = nn.Linear(in_features = 200, out_features = 200)\n",
    "        self.layer4      = nn.Linear(in_features = 200, out_features = 200)\n",
    "        self.layer5      = nn.Linear(in_features = 200, out_features = 132)\n",
    "        self.layer6      = nn.Linear(in_features = 132, out_features = 100)\n",
    "        self.output      = nn.Linear(in_features = 100, out_features = 10)\n",
    "#--------------------forward pass---------------------------------------------------------------------#\n",
    "    def forward(self,t):\n",
    "        t = t.flatten(start_dim=1)\n",
    "        #t = t.reshape(-1)\n",
    "        #t = t.flatten(start_dim = 0)\n",
    "        #print(\"tensor_input_size\", t.size())\n",
    "        t = F.relu(self.input_layer(t))\n",
    "        t = F.relu(self.layer2(t))\n",
    "        t = F.relu(self.layer3(t))\n",
    "        t = F.relu(self.layer4(t))\n",
    "        t = F.relu(self.layer5(t))\n",
    "        t = F.relu(self.layer6(t))\n",
    "        t = self.output(t)\n",
    "        #print(t.item())\n",
    "        #print(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate and network setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = 0.01\n",
    "#policy_net = DQN(600,850).to(device = \"cpu\")\n",
    "#target_net = DQN(600,850).to(device = \"cpu\")\n",
    "#target_net.load_state_dict(policy_net.state_dict()) #set weights to be the same\n",
    "#target_net.eval() #not in training mode\n",
    "#optimizer = optim.Adam(params = policy_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q values setup (fix this up abit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_Values():\n",
    "    device = \"cpu\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_current(policy_net, states, actions):\n",
    "        print(\"action shape\", actions.shape)\n",
    "        actions = actions.squeeze()\n",
    "        print(\"action shape\", actions.shape)\n",
    "        #print(\"states shape\",states.shape)\n",
    "        #return policy_net(states).gather(index=actions.unsqueeze(-1))\n",
    "        return policy_net(states).gather(dim=1, index=actions.unsqueeze(1))\n",
    "    \n",
    "    @staticmethod        \n",
    "    def get_next(target_net, next_states):\n",
    "        #print(\"nx\",next_states)\n",
    "        #print(\"shape\", next_states.shape[0])\n",
    "        final_state_locations = next_states.flatten(start_dim=1).max(dim=1)[0].eq(0).type(torch.bool)\n",
    "        print(\"ft\",final_state_locations)\n",
    "        non_final_state_locations = (final_state_locations == False)\n",
    "        print(\"nf\",non_final_state_locations)\n",
    "        non_final_states = next_states[non_final_state_locations]\n",
    "        batch_size = next_states.shape[0]\n",
    "        values = torch.zeros(batch_size).to(Q_Values.device)\n",
    "        #values = torch.zeros(2).to(Q_Values.device)\n",
    "        values[non_final_state_locations] = target_net(non_final_states).max(dim=1)[0].detach()\n",
    "        return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tensors(experiences):\n",
    "    batch = Xp(*zip(*experiences))\n",
    "    t1 = torch.stack(batch.state) #stack\n",
    "    print(\"t1\",t1)\n",
    "    t2 = torch.stack(batch.action)\n",
    "    print(\"t2\",t2)\n",
    "    t3 = torch.stack(batch.reward)\n",
    "    print(\"t3\",t3)\n",
    "    t4 = torch.stack(batch.next_state)\n",
    "    print(\"t4\",t4)\n",
    "    \n",
    "    \n",
    "    return t1,t2,t3,t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------DEJAVU----------------------------------------------------------#\n",
    "class ReplayMemory():\n",
    "    def __init__(self,capacity):   \n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.push_count = 0\n",
    "        \n",
    "    def push(self, experience):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            #overwrite old memory\n",
    "            self.memory[self.push_count%self.capacity] = experience\n",
    "        self.push_count+=1\n",
    "    #number of returned memories will be equal to batch size\n",
    "    def sample(self, batch_size):\n",
    "        return rand.sample(self.memory,batch_size)\n",
    "    #sample must be equal to batch size\n",
    "    def can_provide_sample(self, batch_size):\n",
    "        return len(self.memory)>=batch_size\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epsilon Decay Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Greed():\n",
    "    def __init__(self,start,end,decay):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.decay = decay\n",
    "    def get_exploration_rate(self,current_step):\n",
    "        return self.end + (self.start - self.end)*math.exp(-1. * current_step*self.decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ReplayMemory(100000)\n",
    "gamma = 0.7 #affects network\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h = blue_template.shape[::-1]  #set template shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "policy_net = DQN(600,850).to(device = \"cpu\")\n",
    "target_net = DQN(600,850).to(device = \"cpu\")\n",
    "target_net.load_state_dict(policy_net.state_dict()) #set weights to be the same\n",
    "target_net.eval() #not in training mode\n",
    "optimizer = optim.Adam(params = policy_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(values, moving_avg_period):\n",
    "    plt.figure(2)\n",
    "    plt.clf()        \n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(values)\n",
    "    \n",
    "    moving_avg = get_moving_average(moving_avg_period, values)\n",
    "    plt.plot(moving_avg)    \n",
    "    plt.pause(0.001)\n",
    "    print(\"Episode\", len(values), \"\\n\", \\\n",
    "          moving_avg_period, \"episode moving avg:\", moving_avg[-1])\n",
    "    if is_ipython: display.clear_output(wait=True)\n",
    "\n",
    "def get_moving_average(period, values):\n",
    "    values = torch.tensor(values, dtype=torch.float)\n",
    "    if len(values) >= period:\n",
    "        moving_avg = values.unfold(dimension=0, size=period, step=1) \\\n",
    "            .mean(dim=1).flatten(start_dim=0)\n",
    "        moving_avg = torch.cat((torch.zeros(period-1), moving_avg))\n",
    "        return moving_avg.numpy()\n",
    "    else:\n",
    "        moving_avg = torch.zeros(len(values))\n",
    "        return moving_avg.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state torch.Size([1, 600, 850])\n",
      "click\n",
      "n torch.Size([1])\n",
      "current_blocks1 21 past_blocks1 21\n",
      "reward_tensor1 tensor([-1.])\n",
      "nxt_sts torch.Size([1, 600, 850])\n",
      "sampling\n",
      "t1 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "t2 tensor([[2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [6],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]])\n",
      "t3 tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [ 2.],\n",
      "        [-1.],\n",
      "        [-4.],\n",
      "        [-1.],\n",
      "        [-1.]])\n",
      "t4 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "action shape torch.Size([50, 1])\n",
      "action shape torch.Size([50])\n",
      "ft tensor([ True, False,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True,  True, False,  True,\n",
      "         True, False,  True, False, False,  True, False,  True,  True,  True,\n",
      "        False,  True,  True,  True,  True, False,  True, False,  True,  True,\n",
      "        False, False,  True, False,  True,  True,  True,  True, False, False],\n",
      "       dtype=torch.bool)\n",
      "nf tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1], dtype=torch.uint8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\scowt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:114: UserWarning: Using a target size (torch.Size([50, 1, 50])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click\n",
      "n torch.Size([1])\n",
      "nxt_sts torch.Size([1, 600, 850])\n",
      "sampling\n",
      "t1 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "t2 tensor([[0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [8],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2]])\n",
      "t3 tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [ 2.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [-1.],\n",
      "        [-4.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-4.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [ 1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-4.],\n",
      "        [-1.],\n",
      "        [-1.]])\n",
      "t4 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "action shape torch.Size([50, 1])\n",
      "action shape torch.Size([50])\n",
      "ft tensor([False,  True,  True, False, False, False, False,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         True,  True,  True,  True, False, False,  True,  True,  True,  True,\n",
      "        False, False,  True,  True, False,  True, False, False,  True,  True,\n",
      "        False,  True,  True, False,  True,  True,  True,  True,  True,  True],\n",
      "       dtype=torch.bool)\n",
      "nf tensor([1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0], dtype=torch.uint8)\n",
      "Exiting loop...\n",
      "updated policy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-b3e75b8350d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"updated policy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mtarget_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     \u001b[0mexp_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_rate\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_rate\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mexp_decay\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\scowt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    761\u001b[0m                     \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m         \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\scowt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(module, prefix)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m                     \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\scowt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(module, prefix)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mlocal_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             module._load_from_state_dict(\n\u001b[1;32m--> 758\u001b[1;33m                 state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n\u001b[0m\u001b[0;32m    759\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\scowt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_load_from_state_dict\u001b[1;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[0;32m    708\u001b[0m                     \u001b[0minput_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m                     \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m                     error_msgs.append('While copying the parameter named \"{}\", '\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#def launch():\n",
    "exp_rate = 1\n",
    "episode = 0\n",
    "max_rate = 1\n",
    "min_rate = 0.01\n",
    "exp_decay = 0.001\n",
    "reward_count = 0\n",
    "for n in range (200):\n",
    "    w,h = blue_template.shape[::-1]  #set template shape\n",
    "    count = 0\n",
    "    current_blocks = initial_block_value\n",
    "    past_blocks = initial_block_value\n",
    "    reward = 0\n",
    "    time.sleep(7) #delay\n",
    "    bounding_box = {'top': 200, 'left': 630, 'width': 850, 'height': 600} #top left corner of screen\n",
    "    #bounding_box = {'top': 200, 'left': 600, 'width': 850, 'height': 600} \n",
    "    sct = mss()\n",
    "    sct_img =(sct.grab(bounding_box))\n",
    "    sct_img = cv2.cvtColor(np.array(sct_img), cv2.COLOR_BGR2GRAY)\n",
    "    first_example = transform_screen_data1(sct_img) #Transform screen(current screen)/previous\n",
    "    sct_img =(sct.grab(bounding_box))\n",
    "    sct_img = cv2.cvtColor(np.array(sct_img), cv2.COLOR_BGR2GRAY)\n",
    "    second_example = transform_screen_data1(sct_img) #Transform screen(current screen)/previous\n",
    "    example = second_example - first_example\n",
    "    state = example\n",
    "    state = state.squeeze().unsqueeze(dim=0)\n",
    "    print(\"initial state\", state.shape)\n",
    "    done = False\n",
    "    while done is not True:\n",
    "        #10 outputs(mouse positions)\n",
    "        init_random = np.random.uniform(0,1)\n",
    "        past_blocks = current_blocks\n",
    "        count+=1\n",
    "        print(\"click\")\n",
    "        x,y = pyautogui.position()\n",
    "        pyautogui.click(x, y)\n",
    "###############################################ACTION########################################################\n",
    "        #epsilon greed\n",
    "        exp_thresh = rand.uniform(0,1)\n",
    "        if exp_thresh < exp_rate:\n",
    "             with torch.no_grad():#need to review this\n",
    "                action = policy_net(state).argmax(dim=1).to(device =\"cpu\")#argmat was -1\n",
    "                print(\"n\",action.shape)\n",
    "        else:\n",
    "            rndm = rand.randrange(0,9)\n",
    "            action = torch.tensor([rndm]).to(device = \"cpu\")\n",
    "            print(\"rand_value\", action)\n",
    "        take_actions(action)\n",
    "#############################################REWARD########################################################### \n",
    "        sct_img =(sct.grab(bounding_box))\n",
    "        gray = cv2.cvtColor(np.array(sct_img), cv2.COLOR_BGR2GRAY) #block detection\n",
    "        f = set()\n",
    "        result = cv2.matchTemplate(gray,blue_template, cv2.TM_CCOEFF_NORMED) #match template per frame\n",
    "        loc = np.where(result >=0.9)\n",
    "        for pt in zip(*loc[::-1]):\n",
    "            sensitivity = 100\n",
    "            f.add((round(pt[0]/sensitivity), round(pt[1]/sensitivity)))\n",
    "        found_count = len(f) # reward factor\n",
    "        current_blocks = found_count\n",
    "        #reward feed to network(onl give reard if resulting action is not a black screen)\n",
    "        if np.average(gray) > 20:\n",
    "            if(current_blocks < past_blocks):\n",
    "                print(\"current_blocks\", current_blocks,\"past_blocks\",past_blocks )\n",
    "                reward =(past_blocks - current_blocks)\n",
    "                reward_count+=reward\n",
    "                print(\"sub\",reward)\n",
    "                reward = torch.FloatTensor([reward], device = \"cpu\")\n",
    "                print(\"reward_tensor0\",reward)\n",
    "                \n",
    "            else:\n",
    "                print(\"current_blocks1\", current_blocks,\"past_blocks1\",past_blocks )\n",
    "                reward = -1\n",
    "                reward_count+=reward\n",
    "                reward = torch.FloatTensor([reward], device = \"cpu\")\n",
    "                print(\"reward_tensor1\",reward)\n",
    "        else:\n",
    "            done = True\n",
    "            #print(\"its dark\")\n",
    "            reward = -4\n",
    "            reward = torch.FloatTensor([reward], device = \"cpu\")\n",
    "        \n",
    "        #from that action i got this state\n",
    "        #sct_img =(sct.grab(bounding_box))\n",
    "        #gray1 = cv2.cvtColor(np.array(sct_img), cv2.COLOR_BGR2GRAY) #block detection\n",
    "#########################################NEXT_STATE############################################################        \n",
    "        # if resulting action is a black screen\n",
    "        if(np.average(gray) < 20):\n",
    "            screen_return = torch.zeros_like(state)\n",
    "            done = True\n",
    "        else:\n",
    "            sct_img =(sct.grab(bounding_box))\n",
    "            sct_img = cv2.cvtColor(np.array(sct_img), cv2.COLOR_BGR2GRAY)\n",
    "            second_example2 = transform_screen_data1(sct_img)\n",
    "            sct_img =(sct.grab(bounding_box))\n",
    "            sct_img = cv2.cvtColor(np.array(sct_img), cv2.COLOR_BGR2GRAY)\n",
    "            second_example3 = transform_screen_data1(sct_img)\n",
    "            \n",
    "            screen_return = second_example3-second_example2 #(Current minus previous)\n",
    "        next_state = screen_return\n",
    "        next_state = next_state.squeeze().unsqueeze(dim=0)\n",
    "        print(\"nxt_sts\",next_state.shape)\n",
    "        #print(\"tensor_input_size\", next_state.size())\n",
    "        memory.push(Xp(state,action,next_state,reward))\n",
    "        #print(Xp(state,action,next_state,reward))\n",
    "        state = next_state\n",
    "######################################EXPERIENCE AND Q VALUES##################################################\n",
    "        if memory.can_provide_sample(50):\n",
    "            Xps = memory.sample(50)\n",
    "            print(\"sampling\")\n",
    "            states, actions,rewards,next_states = extract_tensors(Xps)\n",
    "            current_q_values = Q_Values.get_current(policy_net,states,actions)\n",
    "            next_q_values = Q_Values.get_next(target_net,next_states)\n",
    "            target_q_values = (next_q_values *(gamma)) + rewards\n",
    "            loss = F.mse_loss(current_q_values,target_q_values.unsqueeze(1))\n",
    "            optimizer.zero_grad() #zero out gradients to avoid turning towarda a certain direction\n",
    "            loss.backward()\n",
    "            optimizer.step() #back propagate\n",
    "        if np.average(gray) < 20:\n",
    "            done = True\n",
    "            #plot(reward_count, 100)\n",
    "            print(\"Exiting loop...\")\n",
    "            #break\n",
    "        #cv2.imshow('screen', np.array(sct_img))\n",
    "        #if (cv2.waitKey(1) & 0xFF) == ord('q'):\n",
    "            #cv2.destroyAllWindows()\n",
    "            #break\n",
    "    if n % 100 == 0:\n",
    "        print(\"updated policy\")\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "    exp_rate = min_rate + (max_rate - min_rate)*np.exp(-exp_decay * n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
